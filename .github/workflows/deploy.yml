name: Build and Deploy to Cloud Run

on:
  push:
    branches:
      - main

env:
  PROJECT_ID: "durham-weather-466502"
  GAR_LOCATION: "us-east1"
  GAR_REPOSITORY: "weather-data-images"
  JOB_NAME: "weather-data-uploader"
  REGION: "us-east1"

jobs:
  build-and-deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud (OIDC)
      uses: 'google-github-actions/auth@v2'
      with:
        project_id: ${{ env.PROJECT_ID }}
        # Replace the WORKLOAD_IDENTITY_PROVIDER value with the provider
        # resource name you create with the gcloud commands (projects/NUM/locations/global/workloadIdentityPools/POOL/providers/PROVIDER)
        workload_identity_provider: 'projects/441117079833/locations/global/workloadIdentityPools/github-pool/providers/github-provider'
        service_account: 'data-runner@${{ env.PROJECT_ID }}.iam.gserviceaccount.com'

    - name: Set up Cloud SDK
      uses: 'google-github-actions/setup-gcloud@v2'

    - name: Create Artifact Registry repository
      run: |
        gcloud artifacts repositories create ${{ env.GAR_REPOSITORY }} \
          --repository-format=docker \
          --location=${{ env.GAR_LOCATION }} \
          --description="Docker repository for weather data images" \
          --project=${{ env.PROJECT_ID }} || true

    - name: Configure Docker
      run: gcloud auth configure-docker ${{ env.GAR_LOCATION }}-docker.pkg.dev

    - name: Build Docker image
      run: |
        docker build --tag "${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.GAR_REPOSITORY }}/${{ env.JOB_NAME }}:${{ github.sha }}" .

    - name: Push Docker image to Artifact Registry
      run: |
        docker push "${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.GAR_REPOSITORY }}/${{ env.JOB_NAME }}:${{ github.sha }}"

    - name: Deploy to Cloud Run as a Job
      run: |
        gcloud run jobs deploy ${{ env.JOB_NAME }} \
          --image "${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.GAR_REPOSITORY }}/${{ env.JOB_NAME }}:${{ github.sha }}" \
          --region ${{ env.REGION }} \
          --service-account="data-runner@${{ env.PROJECT_ID }}.iam.gserviceaccount.com" \
          --set-env-vars="PROJECT_ID=${{ env.PROJECT_ID }},DB_CREDS_SECRET_ID=prod-db-credentials,TSI_CREDS_SECRET_ID=tsi_creds,WU_API_KEY_SECRET_ID=wu_api_key,GCS_BUCKET=${{ vars.GCS_BUCKET }},GCS_PREFIX=${{ vars.GCS_PREFIX }}" \
          --command="python" \
          --args="src/data_collection/daily_data_collector.py" \
          --quiet

    - name: Sanity checks (temporary)
      run: |
        echo "Verify gcloud authenticated and can access resources"
        # show active account
        gcloud auth list --filter=status:ACTIVE --format="value(account)" || true
        # list bucket (non-destructive)
        gcloud storage ls gs://sensor-data-to-bigquery || true
        # list secret versions (non-sensitive metadata)
        gcloud secrets versions list prod-db-credentials --project=${{ env.PROJECT_ID }} --limit=5 || true
        # list BigQuery tables in dataset `sensors` (non-destructive)
        bq --project_id=${{ env.PROJECT_ID }} ls --max_results=50 durham-weather-466502:sensors || true