name: Data Freshness Check

on:
  schedule:
    - cron: '25 7 * * *' # After daily merge
  workflow_dispatch:

permissions:
  contents: read
  issues: write
  id-token: write

env:
  BQ_PROJECT: durham-weather-466502
  BQ_DATASET: sensors

jobs:
  freshness:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps minimal
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Auth GCP
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_VERIFIER_SA }}
          token_format: access_token

      - name: Run freshness check
        id: freshness
        run: |
          set +e
          python scripts/check_freshness.py --project "$BQ_PROJECT" --dataset "$BQ_DATASET" --table sensor_readings --max-lag-days 1 > freshness.log 2>&1
          EXIT=$?
          echo "exit_code=$EXIT" >> $GITHUB_OUTPUT
          cat freshness.log || true
          exit $EXIT

      - name: Create issue on failure
        if: failure()
        uses: peter-evans/create-issue-from-file@v5
        with:
          title: "Data freshness lag exceeded"
          content-filepath: freshness.log
          labels: monitoring, freshness

      - name: Upload log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: data-freshness-log
          path: freshness.log