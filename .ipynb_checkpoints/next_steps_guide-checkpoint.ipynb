{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3d9874",
   "metadata": {},
   "source": [
    "# ğŸ”¥ Hot Durham Data Management - Next Steps Guide\n",
    "\n",
    "Your automated data management system is now **fully operational**! This notebook will guide you through the recommended next steps to get the most out of your system.\n",
    "\n",
    "## ğŸ¯ Current Status\n",
    "âœ… **Complete data management system** with organized folder structure  \n",
    "âœ… **Automated data collection** scripts for WU and TSI sensors  \n",
    "âœ… **Google Drive integration** for cloud backup and sync  \n",
    "âœ… **Smart scheduling** with cron job support  \n",
    "âœ… **Comprehensive monitoring** and health checks  \n",
    "\n",
    "## ğŸ“‹ What We'll Cover\n",
    "1. **System Configuration Review** - Check current automation settings\n",
    "2. **Automation Setup** - Enable scheduled data pulls\n",
    "3. **Manual Testing** - Verify system functionality\n",
    "4. **Data Analysis** - Start exploring your environmental data\n",
    "5. **Production Monitoring** - Set up ongoing system health checks\n",
    "\n",
    "Let's get started! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b54e9b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import the necessary libraries for configuration and data handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a38c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Add scripts directory to path\n",
    "sys.path.append('scripts')\n",
    "\n",
    "# Import our custom data manager\n",
    "try:\n",
    "    from data_manager import DataManager\n",
    "    print(\"âœ… DataManager imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Could not import DataManager: {e}\")\n",
    "    print(\"Please ensure you're running this from the Hot Durham project directory\")\n",
    "\n",
    "# Set up paths\n",
    "project_root = Path.cwd()\n",
    "config_path = project_root / \"config\" / \"automation_config.json\"\n",
    "logs_path = project_root / \"logs\"\n",
    "data_path = project_root / \"data\"\n",
    "\n",
    "print(f\"ğŸ“ Project root: {project_root}\")\n",
    "print(f\"ğŸ“ Config path: {config_path}\")\n",
    "print(f\"ğŸ“ Data path: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce41ef5",
   "metadata": {},
   "source": [
    "## 2. Load Configuration\n",
    "\n",
    "Let's check your current automation configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load automation configuration\n",
    "try:\n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        print(\"âœ… Configuration loaded successfully\")\n",
    "        print(\"\\nğŸ“‹ Current Configuration:\")\n",
    "        print(json.dumps(config, indent=2))\n",
    "        \n",
    "        # Check key settings\n",
    "        automation_enabled = config.get('automation_enabled', False)\n",
    "        default_pull_type = config.get('default_pull_type', 'weekly')\n",
    "        google_drive_sync = config.get('google_drive_sync', False)\n",
    "        share_email = config.get('share_email', 'Not set')\n",
    "        \n",
    "        print(f\"\\nğŸ”§ Key Settings:\")\n",
    "        print(f\"   ğŸ“… Automation enabled: {'âœ…' if automation_enabled else 'âŒ'} {automation_enabled}\")\n",
    "        print(f\"   ğŸ“Š Default pull type: {default_pull_type}\")\n",
    "        print(f\"   â˜ï¸ Google Drive sync: {'âœ…' if google_drive_sync else 'âŒ'} {google_drive_sync}\")\n",
    "        print(f\"   ğŸ“§ Share email: {share_email}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Configuration file not found. Run './setup_automation.sh' to create it.\")\n",
    "        config = {}\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading configuration: {e}\")\n",
    "    config = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b6277",
   "metadata": {},
   "source": [
    "## 3. Check Automation Status\n",
    "\n",
    "Let's verify if your automated scheduling is properly configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cron jobs\n",
    "print(\"ğŸ” Checking cron job status...\")\n",
    "try:\n",
    "    result = subprocess.run(['crontab', '-l'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        cron_output = result.stdout\n",
    "        hot_durham_jobs = [line for line in cron_output.split('\\n') if 'Hot Durham' in line or 'automated_data_pull' in line]\n",
    "        \n",
    "        if hot_durham_jobs:\n",
    "            print(f\"âœ… Found {len(hot_durham_jobs)} Hot Durham cron job(s):\")\n",
    "            for job in hot_durham_jobs:\n",
    "                print(f\"   ğŸ“… {job}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ No Hot Durham cron jobs found\")\n",
    "            print(\"\\nğŸ’¡ To set up automation, run:\")\n",
    "            print(\"   ./setup_automation.sh\")\n",
    "    else:\n",
    "        print(\"âŒ Could not access crontab. You may need to set up cron permissions.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error checking cron jobs: {e}\")\n",
    "\n",
    "# Check if setup script exists\n",
    "setup_script = project_root / \"setup_automation.sh\"\n",
    "if setup_script.exists():\n",
    "    print(f\"\\nâœ… Setup script found at: {setup_script}\")\n",
    "    print(\"ğŸ’¡ Run './setup_automation.sh' to configure automated scheduling\")\n",
    "else:\n",
    "    print(\"\\nâŒ Setup script not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fd5bb",
   "metadata": {},
   "source": [
    "## 4. Run Manual Data Pull\n",
    "\n",
    "Let's test your system with a manual data pull to ensure everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available scripts\n",
    "scripts_dir = project_root / \"scripts\"\n",
    "automated_script = scripts_dir / \"automated_data_pull.py\"\n",
    "main_script = scripts_dir / \"faster_wu_tsi_to_sheets_async.py\"\n",
    "\n",
    "print(\"ğŸ” Available data collection scripts:\")\n",
    "if automated_script.exists():\n",
    "    print(f\"âœ… Automated script: {automated_script}\")\n",
    "else:\n",
    "    print(f\"âŒ Automated script not found: {automated_script}\")\n",
    "    \n",
    "if main_script.exists():\n",
    "    print(f\"âœ… Main script: {main_script}\")\n",
    "else:\n",
    "    print(f\"âŒ Main script not found: {main_script}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ To run a manual data pull, choose one of these commands:\")\n",
    "print(\"\\nğŸ“Š **Option 1: Quick test (WU only, no sheets)**\")\n",
    "print(\"   python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\")\n",
    "print(\"\\nğŸ“Š **Option 2: Full weekly pull with Google Sheets**\")\n",
    "print(\"   python scripts/automated_data_pull.py --weekly\")\n",
    "print(\"\\nğŸ“Š **Option 3: Main script (creates comprehensive sheets)**\")\n",
    "print(\"   python scripts/faster_wu_tsi_to_sheets_async.py\")\n",
    "\n",
    "print(\"\\nğŸš€ **Ready to test? Uncomment and run one of the commands below:**\")\n",
    "print(\"# Uncomment the line below to run a test:\")\n",
    "print(\"# !python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª MANUAL TEST EXECUTION\n",
    "# Uncomment the line below to run a quick test of your data collection system:\n",
    "\n",
    "# !python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n",
    "\n",
    "# If you want to run a full test with both WU and TSI data plus Google Sheets:\n",
    "# !python scripts/automated_data_pull.py --weekly\n",
    "\n",
    "print(\"â¸ï¸ Manual test execution is commented out.\")\n",
    "print(\"To run a test, uncomment one of the lines above and execute this cell.\")\n",
    "print(\"\\nğŸ’¡ Recommended first test: --weekly --wu-only --no-sheets (fastest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81450330",
   "metadata": {},
   "source": [
    "## 5. Verify Google Drive Sync\n",
    "\n",
    "Let's check if your Google Drive integration is working properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Google Drive credentials\n",
    "creds_dir = project_root / \"creds\"\n",
    "google_creds = creds_dir / \"google_creds.json\"\n",
    "\n",
    "print(\"â˜ï¸ Google Drive Integration Status:\")\n",
    "\n",
    "if google_creds.exists():\n",
    "    print(\"âœ… Google credentials file found\")\n",
    "    try:\n",
    "        # Try to initialize DataManager (which tests Google Drive)\n",
    "        dm = DataManager(str(project_root))\n",
    "        print(\"âœ… DataManager initialized successfully\")\n",
    "        print(\"âœ… Google Drive service appears to be working\")\n",
    "        \n",
    "        # Check for Google Drive sync script\n",
    "        sync_script = scripts_dir / \"google_drive_sync.py\"\n",
    "        if sync_script.exists():\n",
    "            print(\"âœ… Google Drive sync script found\")\n",
    "        else:\n",
    "            print(\"âŒ Google Drive sync script not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error initializing Google Drive: {e}\")\n",
    "        print(\"ğŸ’¡ Check your Google Cloud Console settings and credentials\")\n",
    "else:\n",
    "    print(f\"âŒ Google credentials not found at: {google_creds}\")\n",
    "    print(\"ğŸ’¡ Place your Google service account credentials in the creds/ directory\")\n",
    "\n",
    "# Check for recent sync logs\n",
    "sync_log = logs_path / \"google_drive_sync.log\"\n",
    "if sync_log.exists():\n",
    "    print(f\"\\nğŸ“‹ Recent Google Drive sync activity found in: {sync_log}\")\n",
    "    print(\"ğŸ’¡ You can check the log for sync details\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No Google Drive sync logs found yet\")\n",
    "    print(\"ğŸ’¡ Logs will be created after your first sync operation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d2c9f",
   "metadata": {},
   "source": [
    "## 6. Analyze Logs for Errors\n",
    "\n",
    "Let's check your system logs for any recent errors or warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd01e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check log directory and files\n",
    "print(\"ğŸ“‹ System Logs Analysis:\")\n",
    "print(f\"\\nLogs directory: {logs_path}\")\n",
    "\n",
    "if logs_path.exists():\n",
    "    log_files = list(logs_path.glob(\"*.log\")) + list(logs_path.glob(\"*.json\"))\n",
    "    \n",
    "    if log_files:\n",
    "        print(f\"\\nğŸ“ Found {len(log_files)} log file(s):\")\n",
    "        for log_file in log_files:\n",
    "            print(f\"   ğŸ“„ {log_file.name} ({log_file.stat().st_size} bytes)\")\n",
    "            \n",
    "        # Check the most recent automation log\n",
    "        json_logs = [f for f in log_files if f.suffix == '.json']\n",
    "        if json_logs:\n",
    "            latest_log = max(json_logs, key=lambda f: f.stat().st_mtime)\n",
    "            print(f\"\\nğŸ“‹ Latest automation log: {latest_log.name}\")\n",
    "            try:\n",
    "                with open(latest_log, 'r') as f:\n",
    "                    log_data = json.load(f)\n",
    "                print(f\"   ğŸ“Š Contains {len(log_data)} log entries\")\n",
    "                if log_data:\n",
    "                    latest_entry = log_data[-1]\n",
    "                    print(f\"   â° Latest entry: {latest_entry.get('timestamp', 'Unknown time')}\")\n",
    "                    print(f\"   ğŸ“Š Status: {latest_entry.get('status', 'Unknown')}\")\n",
    "                    if 'error' in latest_entry:\n",
    "                        print(f\"   âŒ Error: {latest_entry['error']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Error reading log: {e}\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No log files found yet\")\n",
    "        print(\"ğŸ’¡ Logs will be created after running data pulls or automation\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Logs directory not found\")\n",
    "    print(\"ğŸ’¡ Directory will be created automatically when needed\")\n",
    "\n",
    "# Quick error check across all logs\n",
    "if logs_path.exists():\n",
    "    error_count = 0\n",
    "    warning_count = 0\n",
    "    for log_file in logs_path.glob(\"*.log\"):\n",
    "        try:\n",
    "            with open(log_file, 'r') as f:\n",
    "                content = f.read()\n",
    "                error_count += content.lower().count('error')\n",
    "                warning_count += content.lower().count('warning')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if error_count > 0 or warning_count > 0:\n",
    "        print(f\"\\nâš ï¸ Found {error_count} errors and {warning_count} warnings in logs\")\n",
    "        print(\"ğŸ’¡ Use 'grep -i error logs/*.log' to investigate specific issues\")\n",
    "    else:\n",
    "        print(\"\\nâœ… No obvious errors or warnings found in logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d7d6b",
   "metadata": {},
   "source": [
    "## 7. Inspect Data Inventory\n",
    "\n",
    "Let's review your current data collection and storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fe856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataManager to get data inventory\n",
    "print(\"ğŸ“Š Data Inventory Report:\")\n",
    "\n",
    "try:\n",
    "    # Initialize DataManager\n",
    "    dm = DataManager(str(project_root))\n",
    "    \n",
    "    # Get data inventory\n",
    "    inventory = dm.get_data_inventory()\n",
    "    \n",
    "    print(f\"\\nğŸ“ Data Storage Overview:\")\n",
    "    print(f\"   ğŸ“‚ Total files: {inventory.get('total_files', 0)}\")\n",
    "    print(f\"   ğŸ’¾ Total size: {inventory.get('total_size_mb', 0):.2f} MB\")\n",
    "    print(f\"   ğŸ“… Date range: {inventory.get('date_range', 'No data')}\")\n",
    "    \n",
    "    # Break down by source\n",
    "    sources = inventory.get('sources', {})\n",
    "    if sources:\n",
    "        print(f\"\\nğŸ“Š Data by Source:\")\n",
    "        for source, data in sources.items():\n",
    "            print(f\"   ğŸŒ¡ï¸ {source.upper()}: {data.get('files', 0)} files, {data.get('size_mb', 0):.2f} MB\")\n",
    "    \n",
    "    # List recent files\n",
    "    recent_files = inventory.get('recent_files', [])\n",
    "    if recent_files:\n",
    "        print(f\"\\nğŸ“‹ Recent Data Files (last 5):\")\n",
    "        for file_info in recent_files[-5:]:\n",
    "            print(f\"   ğŸ“„ {file_info.get('name', 'Unknown')} ({file_info.get('size_mb', 0):.2f} MB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error getting data inventory: {e}\")\n",
    "    print(\"ğŸ’¡ Try running a manual data pull first to create some data\")\n",
    "\n",
    "# Manual file count (backup method)\n",
    "print(f\"\\nğŸ” Manual Directory Check:\")\n",
    "raw_pulls_dir = data_path / \"raw_pulls\"\n",
    "if raw_pulls_dir.exists():\n",
    "    wu_files = list((raw_pulls_dir / \"wu\").rglob(\"*.csv\")) if (raw_pulls_dir / \"wu\").exists() else []\n",
    "    tsi_files = list((raw_pulls_dir / \"tsi\").rglob(\"*.csv\")) if (raw_pulls_dir / \"tsi\").exists() else []\n",
    "    \n",
    "    print(f\"   ğŸŒ¤ï¸ WU files: {len(wu_files)}\")\n",
    "    print(f\"   ğŸ”¬ TSI files: {len(tsi_files)}\")\n",
    "    \n",
    "    if wu_files or tsi_files:\n",
    "        print(f\"\\nğŸ“‹ Sample files:\")\n",
    "        for f in (wu_files + tsi_files)[:3]:\n",
    "            print(f\"   ğŸ“„ {f.name}\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Raw data directory not found\")\n",
    "    print(\"   ğŸ’¡ Run a data pull to create the directory structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecbe58",
   "metadata": {},
   "source": [
    "## ğŸ¯ Your Recommended Next Steps\n",
    "\n",
    "Based on your system status, here are the recommended next steps:\n",
    "\n",
    "### ğŸš€ **Immediate Actions (Do Today)**\n",
    "\n",
    "1. **Set Up Automation** (If not already done)\n",
    "   ```bash\n",
    "   ./setup_automation.sh\n",
    "   ```\n",
    "\n",
    "2. **Run Your First Test**\n",
    "   ```bash\n",
    "   python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n",
    "   ```\n",
    "\n",
    "3. **Verify Everything Works**\n",
    "   ```bash\n",
    "   python scripts/status_check.py\n",
    "   ```\n",
    "\n",
    "### ğŸ“Š **Short Term (This Week)**\n",
    "\n",
    "4. **Start Regular Data Collection**\n",
    "   - Let the automation run weekly (every Monday 6 AM)\n",
    "   - Or run manual pulls as needed\n",
    "\n",
    "5. **Explore Your Data**\n",
    "   - Check the Google Sheets created by your pulls\n",
    "   - Review data quality and completeness\n",
    "   - Look for interesting patterns or anomalies\n",
    "\n",
    "6. **Set Up Monitoring**\n",
    "   - Check logs weekly for any errors\n",
    "   - Monitor Google Drive sync status\n",
    "   - Verify data integrity regularly\n",
    "\n",
    "### ğŸ“ˆ **Medium Term (This Month)**\n",
    "\n",
    "7. **Data Analysis & Insights**\n",
    "   - Create custom analysis notebooks\n",
    "   - Build dashboards or reports\n",
    "   - Compare WU vs TSI sensor readings\n",
    "   - Analyze seasonal or weekly patterns\n",
    "\n",
    "8. **System Optimization**\n",
    "   - Fine-tune automation schedules\n",
    "   - Add custom data processing\n",
    "   - Optimize Google Drive storage\n",
    "\n",
    "### ğŸ”¬ **Long Term (Ongoing)**\n",
    "\n",
    "9. **Environmental Research**\n",
    "   - Correlate data with health outcomes\n",
    "   - Study air quality trends\n",
    "   - Share insights with Durham community\n",
    "   - Publish findings or reports\n",
    "\n",
    "10. **System Enhancement**\n",
    "    - Add new data sources\n",
    "    - Integrate with other platforms\n",
    "    - Build public dashboards\n",
    "    - Automate report generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89602ec",
   "metadata": {},
   "source": [
    "## âš¡ Quick Actions\n",
    "\n",
    "Use these code cells to perform common tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ QUICK SETUP - Run automation setup\n",
    "# Uncomment to run:\n",
    "\n",
    "# !chmod +x setup_automation.sh\n",
    "# !./setup_automation.sh\n",
    "\n",
    "print(\"â¸ï¸ Setup command is commented out.\")\n",
    "print(\"Uncomment the lines above to run the automation setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª QUICK TEST - Run a fast data pull test\n",
    "# Uncomment to run:\n",
    "\n",
    "# !python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n",
    "\n",
    "print(\"â¸ï¸ Test command is commented out.\")\n",
    "print(\"Uncomment the line above to run a quick WU data test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab81ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š QUICK STATUS - Check system health\n",
    "# Uncomment to run:\n",
    "\n",
    "# !python scripts/status_check.py\n",
    "\n",
    "print(\"â¸ï¸ Status check command is commented out.\")\n",
    "print(\"Uncomment the line above to run a system status check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639779d",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "Your **Hot Durham Data Management System** is ready for production! ğŸš€\n",
    "\n",
    "### âœ… What You've Accomplished:\n",
    "- **Complete automated data collection** system\n",
    "- **Organized storage** with smart file management\n",
    "- **Google Drive integration** for cloud backup\n",
    "- **Scheduling system** for regular data pulls\n",
    "- **Monitoring and logging** for system health\n",
    "- **Comprehensive testing** and validation\n",
    "\n",
    "### ğŸ¯ What's Next:\n",
    "1. **Run the setup** to enable automation\n",
    "2. **Test your first data pull** to verify everything works\n",
    "3. **Let the system collect data** automatically\n",
    "4. **Explore and analyze** your environmental data\n",
    "5. **Share insights** with the Durham community\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** \n",
    "- ğŸ“– Check the `DATA_MANAGEMENT_README.md` for detailed documentation\n",
    "- ğŸ” Use `python scripts/status_check.py` for system health monitoring\n",
    "- ğŸ“‹ Review logs in the `logs/` directory for troubleshooting\n",
    "\n",
    "**Happy data collecting!** ğŸŒŸğŸ“ŠğŸ”¬"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
